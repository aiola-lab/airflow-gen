{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e623dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code will generahe airflow and dbt from jupyer notebook\n",
    "written by: Geva \n",
    "Date: 15/7/2022\n",
    "based on and using:\n",
    "    https://github.com/ajbosco/dag-factory\n",
    "\"\"\"\n",
    "import json\n",
    "import logging \n",
    "import random\n",
    "import yaml,uuid\n",
    "import os\n",
    "logging.getLogger().setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593a3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIRFLOW_PATH = '/home/ec2-user/airflow/dags'\n",
    "RUNNER_SUFFIX = '_runner.py'\n",
    "OWNER = 'aiola@gad-co.ml'\n",
    "MANIFEST_TYPE = 'yaml'\n",
    "manifest_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5648a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_rand_name():\n",
    "    # animals list from https://gist.githubusercontent.com/atduskgreg/3cf8ef48cb0d29cf151bedad81553a54/raw/82f142562cf50b0f6fb8010f890b2f934093553e/animals.txt\n",
    "    words_f = 'animals.txt'\n",
    "    with open(words_f) as l_file:\n",
    "        l_words=l_file.read().split()\n",
    "        return random.choice(l_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86460f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_to_handle = input('Enter Jupyter Notebook :')\n",
    "file_to_handle = False\n",
    "if not file_to_handle or file_to_handle.isspace(): file_to_handle = 'base.ipynb'\n",
    "# owner = input('Enter writer :')\n",
    "owner = False\n",
    "if not owner or owner.isspace(): owner = OWNER\n",
    "logging.debug(f'file to parse {file_to_handle}')\n",
    "logging.debug(owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7560b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_to_handle) as my_ipynb,open('basic.yaml') as air_f_t:\n",
    "    my_ipynb_j = json.loads(my_ipynb.read())\n",
    "    air_flow_struct = yaml.safe_load(air_f_t.read())\n",
    "proj_name = f_rand_name()\n",
    "f_uid = str(uuid.uuid1())\n",
    "logging.debug(proj_name)\n",
    "logging.debug(f_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe72cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task structure :\n",
    "#{'tasks':'task_X': {'operator': 'airflow.operators.bash_operator.BashOperator',\n",
    "#     'bash_command': 'echo 3',\n",
    "#     'dependencies': ['task_1']}}\n",
    "def cre_task(seq=1,operator='airflow.operators.bash_operator.BashOperator',**params):\n",
    "    \"\"\"\n",
    "    Creating task dict for the dag yaml \n",
    "    the keys of the dict is the parameters of the operator as they are in airflow \n",
    "        parameters:\n",
    "            sql : task seq \n",
    "        operator : the airflow operator to run\"\"\"\n",
    "    return{f'task_{seq}':{'operator':operator} | {key:value for key,value in params.items()}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a33e8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cre_run_file(proj_name='gad_1',file_loc=\"\",base_file=\"general_runner.py\",f_sufix=RUNNER_SUFFIX,dest_loc=AIRFLOW_PATH):\n",
    "    import re\n",
    "    \n",
    "    with open(f\"{file_loc}{base_file}\") as tempLate, open(f\"{file_loc}{proj_name}{f_sufix}\" ,'w') as out_f:\n",
    "        for n,txt in enumerate(tempLate):\n",
    "            if n!=3:\n",
    "                out_f.write(txt)\n",
    "            else:\n",
    "                logging.debug(txt)\n",
    "                out_f.write(txt.replace('/path/to/dags/config_file.yml',f\"{dest_loc}/{proj_name}.yml\"))\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14cd8cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_1': {'operator': 'airflow.operators.bash_operator.BashOperator',\n",
       "  'bash_command': 'echo 1',\n",
       "  'dependencies': ['task_1', 'task_2']}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exmple for execution \n",
    "# cre_task(1,operator='airflow.operators.bash_operator.BashOperator',bash_command= 'echo 1',dependencies=['task_1','task_2'])\n",
    "cre_task(1,bash_command= 'echo 1',dependencies=['task_1','task_2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23564b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Marmoset': {'default_args': {'owner': 'aiola@gad-co.ml',\n",
       "   'start_date': datetime.date(2018, 1, 1),\n",
       "   'end_date': datetime.date(2018, 1, 5),\n",
       "   'retries': 1,\n",
       "   'retry_delay_sec': 300},\n",
       "  'schedule_interval': '0 3 * * *',\n",
       "  'concurrency': 1,\n",
       "  'max_active_runs': 1,\n",
       "  'dagrun_timeout_sec': 60,\n",
       "  'default_view': 'tree',\n",
       "  'orientation': 'LR',\n",
       "  'description': 'this is auto generated pipeline by gad-co.ml',\n",
       "  'on_success_callback_name': 'print_hello',\n",
       "  'on_success_callback_file': '/usr/local/airflow/dags/print_hello.py',\n",
       "  'on_failure_callback_name': 'print_hello',\n",
       "  'on_failure_callback_file': '/usr/local/airflow/dags/print_hello.py',\n",
       "  'tasks': {'task_1': {'operator': 'airflow.operators.bash_operator.BashOperator',\n",
       "    'bash_command': 'echo 1'},\n",
       "   'task_2': {'operator': 'airflow.operators.bash_operator.BashOperator',\n",
       "    'bash_command': 'echo 2',\n",
       "    'dependencies': ['task_1']},\n",
       "   'task_3': {'operator': 'airflow.operators.bash_operator.BashOperator',\n",
       "    'bash_command': 'echo 3',\n",
       "    'dependencies': ['task_1']}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#start building the dict\n",
    "air_flow_struct[proj_name]=air_flow_struct.pop('example_dag1')\n",
    "air_flow_struct[proj_name]['default_args']['owner']=owner\n",
    "air_flow_struct\n",
    "# Task structure, under root \n",
    "# tasks:\n",
    "#     task_1:\n",
    "#       operator: airflow.operators.bash_operator.BashOperator\n",
    "#       bash_command: 'echo 1'\n",
    "#     task_2:\n",
    "#       operator: airflow.operators.bash_operator.BashOperator\n",
    "#       bash_command: 'echo 2'\n",
    "#       dependencies: [task_1]\n",
    "#     task_3:\n",
    "#       operator: airflow.operators.bash_operator.BashOperator\n",
    "#       bash_command: 'echo 3'\n",
    "#       dependencies: [task_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1d54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dedicated dir for all ipynb file \n",
    "try:\n",
    "    os.mkdir(proj_name)\n",
    "except:\n",
    "    logging.error(f'dir {proj_name} already exists')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64cafa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fce6e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['print_hello',\n",
       " '/usr/local/airflow/dags/print_hello.py',\n",
       " 'print_hello',\n",
       " '/usr/local/airflow/dags/print_hello.py']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[air_flow_struct[proj_name].pop(x) for x in ['on_success_callback_name','on_success_callback_file','on_failure_callback_name','on_failure_callback_file']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "822a9d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['default_args', 'schedule_interval', 'concurrency', 'max_active_runs', 'dagrun_timeout_sec', 'default_view', 'orientation', 'description', 'tasks'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_flow_struct[proj_name].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f77b0445",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#start \n",
    "IMPORT_TAG = 'import'\n",
    "inpynb_tmplate = my_ipynb_j.copy()\n",
    "inpynb_tmplate['cells']=[]\n",
    "import_cells = []\n",
    "all_nb = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3516452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "new_nb = inpynb_tmplate.copy()\n",
    "new_cells =[]\n",
    "first_cell = True\n",
    "\n",
    "for n,cell in enumerate(my_ipynb_j['cells']):\n",
    "    logging.debug(n)\n",
    "    try:\n",
    "        if IMPORT_TAG in cell['metadata']['tags']:\n",
    "            import_cells.append(cell)\n",
    "            continue\n",
    "    except KeyError:\n",
    "        pass\n",
    "    logging.debug('afetr if 1')\n",
    "    if first_cell:\n",
    "        new_cells.append(cell)\n",
    "        first_cell = False\n",
    "        logging.debug('in if first')\n",
    "    else:\n",
    "        try:\n",
    "            if new_cells and new_cells[-1]['metadata'] == cell['metadata']:\n",
    "                new_cells.append(cell)\n",
    "            elif new_cells and new_cells[-1]['metadata']['tags'] == cell['metadata']['tags']:\n",
    "                new_cells.append(cell)\n",
    "            else:\n",
    "                \n",
    "                new_nb['cells'] = import_cells + new_cells\n",
    "                all_nb.append(new_nb)\n",
    "                print(len(all_nb))\n",
    "                new_nb = inpynb_tmplate.copy()\n",
    "                new_cells = [cell]\n",
    "        except KeyError:\n",
    "            raise()\n",
    "    #the last cell is not line previuse \n",
    "# print(new_cells)\n",
    "new_nb['cells'] = import_cells + new_cells\n",
    "all_nb.append(new_nb)\n",
    "    \n",
    "\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f5fa3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove dumy tasks\n",
    "del air_flow_struct[proj_name]['tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c840a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c96a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = f'{proj_name}/gen_'\n",
    "for n,i in enumerate(all_nb):\n",
    "    f_name = f'{prefix}{file_to_handle.replace(\".ipynb\",\"\")}{n}.ipynb'\n",
    "    with open(f_name,'w') as o_f:\n",
    "        o_f.write(json.dumps(i))\n",
    "#     command = f'\\'> papermill {AIRFLOW_PATH}/{f_name} {AIRFLOW_PATH}/{proj_name}/out/out_{f_name.split(\"/\")[-1]}\\''\n",
    "    command = f\"'{AIRFLOW_PATH}/r.sh {proj_name} {file_to_handle.replace('.ipynb','')} {n}'\"\n",
    "    if n==0:\n",
    "        air_flow_struct[proj_name]['tasks'] = cre_task(n+1,bash_command=command)\n",
    "        manifest_dict['files']=[f_name]\n",
    "    else:\n",
    "        air_flow_struct[proj_name]['tasks'] = air_flow_struct[proj_name]['tasks'] | cre_task(n+1,bash_command=command,dependencies=f'[task_{n}]')\n",
    "        manifest_dict['files'].append(f_name)\n",
    "manifest_dict['proj_name']=proj_name\n",
    "with open(f'{proj_name}_manifest.yml','w') as w_y_p:\n",
    "    yaml.safe_dump_all(manifest_dict,w_y_p)\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8df4e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{proj_name}_tmp.yml\",'w') as w_y_f :\n",
    "    yaml.dump(air_flow_struct,w_y_f)\n",
    "with open(f\"{proj_name}_tmp.yml\") as w_y_f, open(f\"{proj_name}.yml\",'w') as w_o_y_f:\n",
    "    for n,i in enumerate(w_y_f):\n",
    "        w_o_y_f.write(i.replace(\"'''\",\"'\").replace(\"'[\",\"[\").replace(\"]'\",\"]\"))\n",
    "try:\n",
    "    os.remove(f\"{proj_name}_tmp.yml\")\n",
    "except:\n",
    "    logging.error('could not delete tmp file')\n",
    "    \n",
    "cre_run_file(proj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d28c6a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'say done, ready to run, package {proj_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e72739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
